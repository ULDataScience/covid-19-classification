{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "covid-19-classification",
      "display_name": "covid-19-classification"
    },
    "colab": {
      "name": "covid_19_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2b5jlnglWMC",
        "colab_type": "text"
      },
      "source": [
        "## Defining configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRRwIXhDpznF",
        "colab_type": "text"
      },
      "source": [
        "Install lime for explanations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EceoGzclWMD",
        "colab_type": "code",
        "outputId": "aaa68baf-487e-4256-da86-870fcb6fd96c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive_path = ('drive')\n",
        "drive.mount(os.path.join(os.getcwd(), drive_path))\n",
        "tar = tarfile.open(\"/content/drive/My Drive/Colab Notebooks/datasets/data-covid-py.tar.gz\", \"r\")\n",
        "tar.extractall(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDP1HQUqKBX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {\n",
        "  'PATHS': {\n",
        "    'RAW_DATA': os.path.join(os.getcwd(), 'data'),\n",
        "    'COVID_CHEST_XRAY_DATA': os.path.join(os.getcwd(), 'data', 'covid-chestxray-dataset'),\n",
        "    'CHEST_XRAY_8_DATA': os.path.join(os.getcwd(), 'data', 'ChestX-ray8'),\n",
        "    'PROCESSED_DATA': os.path.join(os.getcwd(), 'data', 'processed'),\n",
        "    'TRAIN_SET': os.path.join(os.getcwd(), 'data', 'processed', 'train_set.csv'),\n",
        "    'VAL_SET': os.path.join(os.getcwd(), 'data', 'processed', 'val_set.csv'),\n",
        "    'TEST_SET': os.path.join(os.getcwd(), 'data', 'processed', 'test_set.csv'),\n",
        "    'IMAGES': os.path.join(os.getcwd(), drive_path, 'My Drive', 'Colab Notebooks', 'output', 'documents', 'generated_images'),\n",
        "    'LOGS': os.path.join(os.getcwd(), 'results', 'logs'),\n",
        "    'MODELS_FOLDER': os.path.join(os.getcwd(), drive_path, 'My Drive', 'Colab Notebooks', 'models', 'model_covid'),\n",
        "    'MODEL_WEIGHTS': os.path.join(os.getcwd(), drive_path, 'My Drive', 'Colab Notebooks', 'models', 'model_covid', 'model_weights20200531-103213.index'),\n",
        "    'MODEL_TO_LOAD': os.path.join(os.getcwd(), drive_path, 'My Drive', 'Colab Notebooks', 'models', 'model_covid', 'model20200531-180948.h5'),\n",
        "    'OUTPUT_CLASS_INDICES': os.path.join(os.getcwd(), 'data', 'interpretability', 'output_class_indices.pkl'),\n",
        "    'LIME_EXPLAINER': os.path.join(os.getcwd(), 'data', 'interpretability', 'lime_explainer.pkl'),\n",
        "  },\n",
        "  'DATA': {\n",
        "    'IMG_DIM': [\n",
        "      512,\n",
        "      512\n",
        "    ],\n",
        "    'VIEW': 'PA',\n",
        "    'VAL_SPLIT_PERCENT': 0.08,\n",
        "    'TEST_SPLIT_PERCENT': 0.1,\n",
        "    'NUM_CHEST_XRAY_8_IMAGES': 1000,\n",
        "    'CLASSES': [\n",
        "      'COVID-19',\n",
        "      'OTHER'\n",
        "    ],\n",
        "    'OTHER_CONTAINS_ONLY_HEALTHY': True,\n",
        "    \n",
        "    # One of {'class_weight', 'reduce'}\n",
        "    'CLASS_BALANCE_STRATEGY': 'reduce'      \n",
        "  },\n",
        "  'TRAIN': {\n",
        "    'BATCH_SIZE': 32,\n",
        "    'EPOCHS': 150,\n",
        "    'THRESHOLDS': 0.5,\n",
        "    'ENABLE_EARLY_STOPPING': False,\n",
        "    'PATIENCE_FOR_EARLY_STOPPING': 7,\n",
        "    'NUM_GPUS': 0\n",
        "  },\n",
        "  'NN': {\n",
        "    'KERNEL_SIZE': '(3,3)',\n",
        "    'STRIDES': '(1,1)',\n",
        "    'INIT_FILTERS': 16,\n",
        "    'FILTER_EXP_BASE': 3,\n",
        "    'MAXPOOL_SIZE': '(2,2)',\n",
        "    'CONV_BLOCKS': 3,\n",
        "    'NODES_DENSE0': 128,\n",
        "    'LR': 1e-05,\n",
        "    'OPTIMIZER': 'adam',\n",
        "    'DROPOUT': 0.4,\n",
        "    'L2_LAMBDA': 0.0001\n",
        "  },\n",
        "  'LIME': {\n",
        "    'KERNEL_WIDTH': 1.75,\n",
        "    'FEATURE_SELECTION': 'lasso_path',\n",
        "    'NUM_FEATURES': 1000,\n",
        "    'NUM_SAMPLES': 1000,\n",
        "    'COVID_ONLY': False\n",
        "  },\n",
        "  'PREDICTION': {\n",
        "    'THRESHOLD': 0.5\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4oldNSulWML",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "### Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk12-bl0lWMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "for path in config['PATHS']:\n",
        "    if not bool(re.match('^.*\\.[a-zA-Z0-9]+$', config['PATHS'][path])):\n",
        "        Path(config['PATHS'][path]).mkdir(parents=True, exist_ok=True)\n",
        "    else:\n",
        "        splitted_path = config['PATHS'][path][:config['PATHS'][path].rfind('/')]\n",
        "        Path(splitted_path).mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z89gzdwQND0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "covid_chest_xray_path = config['PATHS']['COVID_CHEST_XRAY_DATA']\n",
        "chest_xray_8_path = config['PATHS']['CHEST_XRAY_8_DATA']\n",
        "\n",
        "covid_chest_xray_df = pd.read_csv(os.path.join(covid_chest_xray_path, 'metadata.csv'))\n",
        "covid_chest_xray_df['filename'] = [os.path.join(covid_chest_xray_path, 'images', row) for row in covid_chest_xray_df['filename'].astype(str)]\n",
        "\n",
        "covid_views_cxrs_df = covid_chest_xray_df['view'].str.match(config['DATA']['VIEW'])\n",
        "covid_pos_df = covid_chest_xray_df['finding'].str.match('COVID-19')\n",
        "covid_df = covid_chest_xray_df[covid_pos_df & covid_views_cxrs_df] \n",
        "\n",
        "chest_xray_8_df = pd.read_csv(os.path.join(chest_xray_8_path, 'subset.csv'))\n",
        "num_chest_xray_8_imgs = config['DATA']['NUM_CHEST_XRAY_8_IMAGES']\n",
        "chest_xray_8_normal_df = chest_xray_8_df[chest_xray_8_df['Finding Labels'].str.match('No Finding')]\n",
        "chest_xray_8_pneum_df = chest_xray_8_df[chest_xray_8_df['Finding Labels'].str.match('(?!No Finding)')]\n",
        "\n",
        "chest_xray_8_normal_sample_df = chest_xray_8_normal_df.sample(frac = num_chest_xray_8_imgs / chest_xray_8_normal_df.shape[0], random_state=num_chest_xray_8_imgs)\n",
        "\n",
        "chest_xray_8_pneum_sample_df = chest_xray_8_pneum_df.sample(frac = num_chest_xray_8_imgs / chest_xray_8_pneum_df.shape[0], random_state=num_chest_xray_8_imgs)\n",
        "\n",
        "if config['DATA']['OTHER_CONTAINS_ONLY_HEALTHY']:\n",
        "  chest_xray_8_df = chest_xray_8_normal_sample_df\n",
        "else:\n",
        "  chest_xray_8_df = pd.concat([chest_xray_8_normal_sample_df, chest_xray_8_pneum_sample_df], axis=0)\n",
        "\n",
        "chest_xray_8_df['filename'] = [os.path.join(chest_xray_8_path, row) for row in chest_xray_8_df['Image Index'].astype(str)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcQqWxwNNHUt",
        "colab_type": "code",
        "outputId": "a8f3aedf-8cdf-4db5-b886-356f05a2853c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "covid_df['label'] = 'COVID-19'\n",
        "chest_xray_8_df['label'] = 'OTHER'\n",
        "\n",
        "chest_xray_8_selected_df = None\n",
        "if config['DATA']['CLASS_BALANCE_STRATEGY'] == 'reduce':\n",
        "  chest_xray_8_selected_df = chest_xray_8_df.head(covid_df.shape[0])\n",
        "else:\n",
        "  chest_xray_8_selected_df = chest_xray_8_df\n",
        "\n",
        "file_df = pd.concat(\n",
        "        [covid_df[['filename', 'label']],\n",
        "        chest_xray_8_selected_df[['filename', 'label']]], axis=0)         "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY-JdrYYNM0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "validation_split_size = config['DATA']['VAL_SPLIT_PERCENT']\n",
        "test_split_size = config['DATA']['TEST_SPLIT_PERCENT']\n",
        "file_df_train, file_df_test = train_test_split(file_df, test_size=test_split_size, stratify=file_df['label'], random_state=42)\n",
        "relative_validation_split_size = validation_split_size / (1 - test_split_size)\n",
        "file_df_train, file_df_val = train_test_split(file_df_train, test_size=relative_validation_split_size,\n",
        "                                                    stratify=file_df_train['label'], random_state=42)\n",
        "\n",
        "if not os.path.exists(config['PATHS']['PROCESSED_DATA']):\n",
        "    os.makedirs(config['PATHS']['PROCESSED_DATA'])\n",
        "file_df_train.to_csv(config['PATHS']['TRAIN_SET'])\n",
        "file_df_val.to_csv(config['PATHS']['VAL_SET'])\n",
        "file_df_test.to_csv(config['PATHS']['TEST_SET'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaKciJeLNTTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "\n",
        "cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "log_dir = os.path.join(config['PATHS']['LOGS'], 'training', cur_date)\n",
        "if not os.path.exists(os.path.join(config['PATHS']['LOGS'], 'training')):\n",
        "    os.makedirs(os.path.join(config['PATHS']['LOGS'], 'training'))\n",
        "\n",
        "data = {}\n",
        "data['TRAIN'] = pd.read_csv(config['PATHS']['TRAIN_SET'])\n",
        "data['VAL'] = pd.read_csv(config['PATHS']['VAL_SET'])\n",
        "data['TEST'] = pd.read_csv(config['PATHS']['TEST_SET'])\n",
        "\n",
        "callbacks = []\n",
        "if config['TRAIN']['ENABLE_EARLY_STOPPING']:\n",
        "  early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    verbose=1, \n",
        "    patience=config['TRAIN']['PATIENCE_FOR_EARLY_STOPPING'], \n",
        "    mode='min', \n",
        "    restore_best_weights=False)\n",
        "  callbacks.append(early_stopping)\n",
        "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "callbacks.append(tensorboard)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPEyRMgNNXPA",
        "colab_type": "code",
        "outputId": "6735fc1b-1a71-4469-c110-b3d70d2c5c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import dill\n",
        "\n",
        "train_img_gen = ImageDataGenerator(rotation_range=10, samplewise_std_normalization=True, samplewise_center=True)\n",
        "val_img_gen = ImageDataGenerator(samplewise_std_normalization=True, samplewise_center=True)\n",
        "test_img_gen = ImageDataGenerator(samplewise_std_normalization=True, samplewise_center=True)\n",
        "\n",
        "img_shape = tuple(config['DATA']['IMG_DIM'])\n",
        "\n",
        "class_mode = 'categorical'\n",
        "train_generator = train_img_gen.flow_from_dataframe(\n",
        "    dataframe=data['TRAIN'],\n",
        "    x_col=\"filename\",\n",
        "    y_col='label',\n",
        "    target_size=img_shape,\n",
        "    batch_size=config['TRAIN']['BATCH_SIZE'],\n",
        "    class_mode=class_mode,\n",
        "    validate_filenames=True)\n",
        "val_generator = val_img_gen.flow_from_dataframe(\n",
        "    dataframe=data['VAL'],\n",
        "    x_col=\"filename\",\n",
        "    y_col='label',\n",
        "    target_size=img_shape,\n",
        "    batch_size=config['TRAIN']['BATCH_SIZE'],\n",
        "    class_mode=class_mode,\n",
        "    validate_filenames=True)\n",
        "test_generator = test_img_gen.flow_from_dataframe(\n",
        "    dataframe=data['TEST'],\n",
        "    x_col=\"filename\",\n",
        "    y_col='label',\n",
        "    target_size=img_shape,\n",
        "    batch_size=config['TRAIN']['BATCH_SIZE'],\n",
        "    class_mode=class_mode,\n",
        "    validate_filenames=True,\n",
        "    shuffle=False)\n",
        "\n",
        "dill.dump(test_generator.class_indices, open(config['PATHS']['OUTPUT_CLASS_INDICES'], 'wb+'))\n",
        "\n",
        "histogram = np.bincount(np.array(train_generator.labels).astype(int))\n",
        "\n",
        "class_weight = None\n",
        "if config['DATA']['CLASS_BALANCE_STRATEGY'] == 'class_weight':\n",
        "  class_multiplier_list = [min(histogram) / max(histogram)]\n",
        "  class_multiplier_list.insert(int(histogram[0] > histogram[1]), 1.0)\n",
        "\n",
        "  class_multiplier = [\n",
        "          class_multiplier_list[config['DATA']['CLASSES'].index(c)]\n",
        "              for c in test_generator.class_indices\n",
        "  ]\n",
        "\n",
        "  weights = [(1.0 / len(histogram)) * sum(histogram) / histogram[i] for i in range(len(histogram))]\n",
        "\n",
        "  class_weight = {i: class_multiplier[i] for i in range(len(histogram))}  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 250 validated image filenames belonging to 2 classes.\n",
            "Found 25 validated image filenames belonging to 2 classes.\n",
            "Found 31 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend"
        ],
        "id": "FKsl3JxqlWMc",
        "colab_type": "code",
        "outputId": "3c5dd3cb-e651-470b-d559-8faf80f56df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall, AUC\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, LeakyReLU, Activation, GlobalMaxPooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.applications import ResNet101V2\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "\n",
        "covid_class_idx = test_generator.class_indices['COVID-19']   \n",
        "thresholds = 1.0 / len(config['DATA']['CLASSES'])\n",
        "metrics = ['accuracy', CategoricalAccuracy(name='c_accuracy'),\n",
        "    Precision(name='precision', thresholds=thresholds, class_id=covid_class_idx),\n",
        "    Recall(name='recall', thresholds=thresholds, class_id=covid_class_idx),\n",
        "    AUC(name='auc'),\n",
        "    F1Score(name='f1score', threshold=thresholds, num_classes=len(config['DATA']['CLASSES']))]\n",
        "\n",
        "input_shape = config['DATA']['IMG_DIM'] + [3]\n",
        "num_gpus = config['TRAIN']['NUM_GPUS']\n",
        "\n",
        "model_config = config['NN']\n",
        "\n",
        "nodes_dense0 = model_config['NODES_DENSE0']\n",
        "lr = model_config['LR']\n",
        "dropout = model_config['DROPOUT']\n",
        "l2_lambda = model_config['L2_LAMBDA']\n",
        "\n",
        "if model_config['OPTIMIZER'] == 'sgd':\n",
        "    optimizer = SGD(learning_rate=lr)\n",
        "else:\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "histogram = np.bincount([config['DATA']['CLASSES'].index(label) for label in data['TRAIN']['label'].astype(str)])\n",
        "output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
        "\n",
        "# Set output bias\n",
        "if output_bias is not None:\n",
        "    output_bias = Constant(output_bias)\n",
        "print(\"MODEL CONFIG: \", model_config)\n",
        "\n",
        "X_input = Input(input_shape, name='input_img')\n",
        "base_model = ResNet101V2(include_top=False, weights='imagenet', input_shape=input_shape, input_tensor=X_input)\n",
        "base_model.trainable = False\n",
        "X = base_model.output\n",
        "\n",
        "# Add custom top\n",
        "X = GlobalMaxPooling2D()(X)\n",
        "X = Dropout(dropout)(X)\n",
        "X = Dense(nodes_dense0, kernel_initializer='he_uniform', activity_regularizer=l2(l2_lambda))(X)\n",
        "X = LeakyReLU()(X)\n",
        "X = Dense(len(config['DATA']['CLASSES']), bias_initializer=output_bias)(X)\n",
        "Y = Activation('softmax', dtype='float32', name='output')(X)\n",
        "\n",
        "model = Model(inputs=X_input, outputs=Y)\n",
        "model.summary()\n",
        "\n",
        "if num_gpus >= 2:\n",
        "    model = multi_gpu_model(model, gpus=num_gpus)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MODEL CONFIG:  {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 3, 'NODES_DENSE0': 128, 'LR': 1e-05, 'OPTIMIZER': 'adam', 'DROPOUT': 0.4, 'L2_LAMBDA': 0.0001}\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "171319296/171317808 [==============================] - 4s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_img (InputLayer)          [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_img[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 128, 128, 64) 256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 128, 128, 64) 0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 128, 128, 256 0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 128, 128, 256 0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 128, 128, 256 0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 64, 64, 256)  0           max_pooling2d[0][0]              \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 64, 64, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 64, 64, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 32, 32, 512)  0           max_pooling2d_1[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 32, 32, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 32, 32, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 32, 32, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block7_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block7_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block7_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_1_relu (Activation (None, 32, 32, 256)  0           conv4_block7_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block7_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block7_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block7_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_2_relu (Activation (None, 32, 32, 256)  0           conv4_block7_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block7_out (Add)          (None, 32, 32, 1024) 0           conv4_block6_out[0][0]           \n",
            "                                                                 conv4_block7_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block7_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block8_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block8_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block8_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_1_relu (Activation (None, 32, 32, 256)  0           conv4_block8_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block8_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block8_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block8_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_2_relu (Activation (None, 32, 32, 256)  0           conv4_block8_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block8_out (Add)          (None, 32, 32, 1024) 0           conv4_block7_out[0][0]           \n",
            "                                                                 conv4_block8_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block8_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block9_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block9_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block9_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_1_relu (Activation (None, 32, 32, 256)  0           conv4_block9_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block9_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block9_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block9_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_2_relu (Activation (None, 32, 32, 256)  0           conv4_block9_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block9_out (Add)          (None, 32, 32, 1024) 0           conv4_block8_out[0][0]           \n",
            "                                                                 conv4_block9_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block9_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block10_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block10_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block10_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block10_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block10_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block10_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block10_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block10_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block10_out (Add)         (None, 32, 32, 1024) 0           conv4_block9_out[0][0]           \n",
            "                                                                 conv4_block10_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block10_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block11_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block11_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block11_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block11_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block11_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block11_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block11_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block11_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block11_out (Add)         (None, 32, 32, 1024) 0           conv4_block10_out[0][0]          \n",
            "                                                                 conv4_block11_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block11_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block12_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block12_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block12_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block12_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block12_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block12_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block12_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block12_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block12_out (Add)         (None, 32, 32, 1024) 0           conv4_block11_out[0][0]          \n",
            "                                                                 conv4_block12_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block12_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block13_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block13_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block13_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block13_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block13_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block13_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block13_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block13_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block13_out (Add)         (None, 32, 32, 1024) 0           conv4_block12_out[0][0]          \n",
            "                                                                 conv4_block13_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block13_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block14_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block14_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block14_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block14_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block14_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block14_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block14_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block14_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block14_out (Add)         (None, 32, 32, 1024) 0           conv4_block13_out[0][0]          \n",
            "                                                                 conv4_block14_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block14_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block15_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block15_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block15_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block15_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block15_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block15_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block15_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block15_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block15_out (Add)         (None, 32, 32, 1024) 0           conv4_block14_out[0][0]          \n",
            "                                                                 conv4_block15_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block15_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block16_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block16_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block16_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block16_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block16_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block16_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block16_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block16_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block16_out (Add)         (None, 32, 32, 1024) 0           conv4_block15_out[0][0]          \n",
            "                                                                 conv4_block16_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block16_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block17_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block17_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block17_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block17_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block17_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block17_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block17_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block17_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block17_out (Add)         (None, 32, 32, 1024) 0           conv4_block16_out[0][0]          \n",
            "                                                                 conv4_block17_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block17_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block18_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block18_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block18_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block18_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block18_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block18_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block18_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block18_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block18_out (Add)         (None, 32, 32, 1024) 0           conv4_block17_out[0][0]          \n",
            "                                                                 conv4_block18_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block18_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block19_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block19_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block19_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block19_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block19_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block19_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block19_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block19_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block19_out (Add)         (None, 32, 32, 1024) 0           conv4_block18_out[0][0]          \n",
            "                                                                 conv4_block19_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block19_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block20_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block20_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block20_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block20_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block20_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block20_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block20_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block20_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block20_out (Add)         (None, 32, 32, 1024) 0           conv4_block19_out[0][0]          \n",
            "                                                                 conv4_block20_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block20_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block21_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block21_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block21_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block21_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block21_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block21_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block21_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block21_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block21_out (Add)         (None, 32, 32, 1024) 0           conv4_block20_out[0][0]          \n",
            "                                                                 conv4_block21_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block21_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block22_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block22_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block22_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block22_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block22_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block22_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block22_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block22_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block22_out (Add)         (None, 32, 32, 1024) 0           conv4_block21_out[0][0]          \n",
            "                                                                 conv4_block22_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block23_preact_bn[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block23_preact_relu[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block23_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block23_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block23_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block23_2_pad[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block23_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block23_2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 1024) 0           conv4_block22_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block23_out (Add)         (None, 16, 16, 1024) 0           max_pooling2d_2[0][0]            \n",
            "                                                                 conv4_block23_3_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block23_out[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 16, 16, 1024) 0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 16, 16, 512)  524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 16, 16, 512)  0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 18, 18, 512)  0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 16, 16, 512)  2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 16, 16, 512)  0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 16, 16, 2048) 2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 16, 16, 2048) 0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 16, 16, 2048) 8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 16, 16, 2048) 0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 16, 16, 512)  1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 16, 16, 512)  0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 18, 18, 512)  0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 16, 16, 512)  2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 16, 16, 512)  0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 16, 16, 2048) 0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 16, 16, 2048) 8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 16, 16, 2048) 0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 16, 16, 512)  1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 16, 16, 512)  0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 18, 18, 512)  0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 16, 16, 512)  2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 16, 16, 512)  0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 16, 16, 2048) 0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 16, 16, 2048) 8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 16, 16, 2048) 0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 2048)         0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2048)         0           global_max_pooling2d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          262272      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            258         leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Activation)             (None, 2)            0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 42,889,090\n",
            "Trainable params: 262,530\n",
            "Non-trainable params: 42,626,560\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "und1kW3rlWMd",
        "colab_type": "code",
        "outputId": "a2b4c087-9c40-431c-f88c-b4abc449b99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from math import ceil\n",
        "\n",
        "steps_per_epoch = ceil(train_generator.n / train_generator.batch_size)\n",
        "val_steps = ceil(val_generator.n / val_generator.batch_size)\n",
        "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=config['TRAIN']['EPOCHS'],\n",
        "                                validation_data=val_generator, validation_steps=val_steps, callbacks=callbacks,\n",
        "                                verbose=True, class_weight=class_weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "8/8 [==============================] - 25s 3s/step - loss: 50.1646 - accuracy: 0.4680 - c_accuracy: 0.4680 - precision: 0.4706 - recall: 0.5120 - auc: 0.4661 - f1score: 0.4670 - val_loss: 21.3661 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5625 - val_recall: 0.7500 - val_auc: 0.6464 - val_f1score: 0.5942\n",
            "Epoch 2/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 46.0837 - accuracy: 0.5440 - c_accuracy: 0.5440 - precision: 0.5433 - recall: 0.5520 - auc: 0.5546 - f1score: 0.5440 - val_loss: 20.3982 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5625 - val_recall: 0.7500 - val_auc: 0.6448 - val_f1score: 0.5942\n",
            "Epoch 3/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 43.9007 - accuracy: 0.5440 - c_accuracy: 0.5440 - precision: 0.5455 - recall: 0.5280 - auc: 0.5552 - f1score: 0.5439 - val_loss: 20.0375 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5294 - val_recall: 0.7500 - val_auc: 0.6272 - val_f1score: 0.5484\n",
            "Epoch 4/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 45.8955 - accuracy: 0.4480 - c_accuracy: 0.4480 - precision: 0.4519 - recall: 0.4880 - auc: 0.4398 - f1score: 0.4471 - val_loss: 19.4386 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5294 - val_recall: 0.7500 - val_auc: 0.6144 - val_f1score: 0.5484\n",
            "Epoch 5/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 41.7396 - accuracy: 0.5440 - c_accuracy: 0.5440 - precision: 0.5455 - recall: 0.5280 - auc: 0.5456 - f1score: 0.5439 - val_loss: 18.6890 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5294 - val_recall: 0.7500 - val_auc: 0.6144 - val_f1score: 0.5484\n",
            "Epoch 6/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 42.2590 - accuracy: 0.5240 - c_accuracy: 0.5240 - precision: 0.5238 - recall: 0.5280 - auc: 0.5151 - f1score: 0.5240 - val_loss: 18.5363 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6096 - val_f1score: 0.5833\n",
            "Epoch 7/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 39.1032 - accuracy: 0.5160 - c_accuracy: 0.5160 - precision: 0.5154 - recall: 0.5360 - auc: 0.5294 - f1score: 0.5158 - val_loss: 17.9640 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6096 - val_f1score: 0.5833\n",
            "Epoch 8/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 40.7169 - accuracy: 0.5280 - c_accuracy: 0.5280 - precision: 0.5248 - recall: 0.5920 - auc: 0.5244 - f1score: 0.5261 - val_loss: 17.2792 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6128 - val_f1score: 0.5833\n",
            "Epoch 9/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 42.7755 - accuracy: 0.4720 - c_accuracy: 0.4720 - precision: 0.4724 - recall: 0.4800 - auc: 0.4515 - f1score: 0.4720 - val_loss: 16.5337 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6160 - val_f1score: 0.5833\n",
            "Epoch 10/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 41.0116 - accuracy: 0.4960 - c_accuracy: 0.4960 - precision: 0.4960 - recall: 0.4960 - auc: 0.4978 - f1score: 0.4960 - val_loss: 15.5568 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5294 - val_recall: 0.7500 - val_auc: 0.6000 - val_f1score: 0.5484\n",
            "Epoch 11/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 39.9464 - accuracy: 0.5120 - c_accuracy: 0.5120 - precision: 0.5120 - recall: 0.5120 - auc: 0.5240 - f1score: 0.5120 - val_loss: 15.5262 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6256 - val_f1score: 0.5833\n",
            "Epoch 12/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 37.8906 - accuracy: 0.5480 - c_accuracy: 0.5480 - precision: 0.5526 - recall: 0.5040 - auc: 0.5453 - f1score: 0.5471 - val_loss: 16.0470 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.5808 - val_f1score: 0.5833\n",
            "Epoch 13/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 35.4882 - accuracy: 0.5440 - c_accuracy: 0.5440 - precision: 0.5433 - recall: 0.5520 - auc: 0.5501 - f1score: 0.5440 - val_loss: 16.9001 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5500 - val_recall: 0.9167 - val_auc: 0.5744 - val_f1score: 0.5660\n",
            "Epoch 14/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 38.6187 - accuracy: 0.4840 - c_accuracy: 0.4840 - precision: 0.4859 - recall: 0.5520 - auc: 0.4946 - f1score: 0.4816 - val_loss: 15.3294 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.5824 - val_f1score: 0.6180\n",
            "Epoch 15/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 38.8842 - accuracy: 0.5240 - c_accuracy: 0.5240 - precision: 0.5214 - recall: 0.5840 - auc: 0.5130 - f1score: 0.5223 - val_loss: 13.8561 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.5904 - val_f1score: 0.5833\n",
            "Epoch 16/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 37.1086 - accuracy: 0.5280 - c_accuracy: 0.5280 - precision: 0.5276 - recall: 0.5360 - auc: 0.5344 - f1score: 0.5280 - val_loss: 12.8042 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5294 - val_recall: 0.7500 - val_auc: 0.6080 - val_f1score: 0.5484\n",
            "Epoch 17/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 36.0741 - accuracy: 0.5360 - c_accuracy: 0.5360 - precision: 0.5385 - recall: 0.5040 - auc: 0.5382 - f1score: 0.5355 - val_loss: 12.5378 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5294 - val_recall: 0.7500 - val_auc: 0.6112 - val_f1score: 0.5484\n",
            "Epoch 18/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 36.4708 - accuracy: 0.5200 - c_accuracy: 0.5200 - precision: 0.5210 - recall: 0.4960 - auc: 0.5259 - f1score: 0.5197 - val_loss: 12.7007 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6112 - val_f1score: 0.5833\n",
            "Epoch 19/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 35.4049 - accuracy: 0.4920 - c_accuracy: 0.4920 - precision: 0.4924 - recall: 0.5200 - auc: 0.4952 - f1score: 0.4916 - val_loss: 12.9061 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.5968 - val_f1score: 0.6180\n",
            "Epoch 20/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 34.7869 - accuracy: 0.5360 - c_accuracy: 0.5360 - precision: 0.5319 - recall: 0.6000 - auc: 0.5454 - f1score: 0.5341 - val_loss: 11.6226 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6144 - val_f1score: 0.5833\n",
            "Epoch 21/150\n",
            "8/8 [==============================] - 24s 3s/step - loss: 32.4323 - accuracy: 0.5520 - c_accuracy: 0.5520 - precision: 0.5556 - recall: 0.5200 - auc: 0.5524 - f1score: 0.5515 - val_loss: 10.8699 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5333 - val_recall: 0.6667 - val_auc: 0.6400 - val_f1score: 0.5572\n",
            "Epoch 22/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 36.5193 - accuracy: 0.5440 - c_accuracy: 0.5440 - precision: 0.5495 - recall: 0.4880 - auc: 0.5130 - f1score: 0.5426 - val_loss: 10.8166 - val_accuracy: 0.5200 - val_c_accuracy: 0.5200 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6256 - val_f1score: 0.5130\n",
            "Epoch 23/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 36.1667 - accuracy: 0.5600 - c_accuracy: 0.5600 - precision: 0.5573 - recall: 0.5840 - auc: 0.5416 - f1score: 0.5597 - val_loss: 11.3535 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6080 - val_f1score: 0.5833\n",
            "Epoch 24/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 33.7143 - accuracy: 0.5480 - c_accuracy: 0.5480 - precision: 0.5469 - recall: 0.5600 - auc: 0.5516 - f1score: 0.5479 - val_loss: 10.3594 - val_accuracy: 0.5200 - val_c_accuracy: 0.5200 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6256 - val_f1score: 0.5130\n",
            "Epoch 25/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 35.0930 - accuracy: 0.5040 - c_accuracy: 0.5040 - precision: 0.5039 - recall: 0.5200 - auc: 0.5075 - f1score: 0.5039 - val_loss: 10.1929 - val_accuracy: 0.5200 - val_c_accuracy: 0.5200 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6256 - val_f1score: 0.5130\n",
            "Epoch 26/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 32.0256 - accuracy: 0.5800 - c_accuracy: 0.5800 - precision: 0.5781 - recall: 0.5920 - auc: 0.5785 - f1score: 0.5799 - val_loss: 10.0133 - val_accuracy: 0.5200 - val_c_accuracy: 0.5200 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6288 - val_f1score: 0.5130\n",
            "Epoch 27/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 33.6207 - accuracy: 0.5000 - c_accuracy: 0.5000 - precision: 0.5000 - recall: 0.4960 - auc: 0.5009 - f1score: 0.5000 - val_loss: 9.8598 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6384 - val_f1score: 0.5833\n",
            "Epoch 28/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 32.3252 - accuracy: 0.5520 - c_accuracy: 0.5520 - precision: 0.5537 - recall: 0.5360 - auc: 0.5384 - f1score: 0.5519 - val_loss: 10.7568 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.5968 - val_f1score: 0.6180\n",
            "Epoch 29/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 33.5578 - accuracy: 0.5440 - c_accuracy: 0.5440 - precision: 0.5455 - recall: 0.5280 - auc: 0.5438 - f1score: 0.5439 - val_loss: 10.1168 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6016 - val_f1score: 0.6180\n",
            "Epoch 30/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 31.6899 - accuracy: 0.5440 - c_accuracy: 0.5440 - precision: 0.5385 - recall: 0.6160 - auc: 0.5474 - f1score: 0.5416 - val_loss: 9.6019 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6336 - val_f1score: 0.6180\n",
            "Epoch 31/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 31.6624 - accuracy: 0.5760 - c_accuracy: 0.5760 - precision: 0.5714 - recall: 0.6080 - auc: 0.5869 - f1score: 0.5756 - val_loss: 8.5934 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5333 - val_recall: 0.6667 - val_auc: 0.6464 - val_f1score: 0.5572\n",
            "Epoch 32/150\n",
            "8/8 [==============================] - 24s 3s/step - loss: 30.9701 - accuracy: 0.5520 - c_accuracy: 0.5520 - precision: 0.5565 - recall: 0.5120 - auc: 0.5566 - f1score: 0.5513 - val_loss: 8.3414 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5833 - val_recall: 0.5833 - val_auc: 0.6192 - val_f1score: 0.5994\n",
            "Epoch 33/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 31.1777 - accuracy: 0.5440 - c_accuracy: 0.5440 - precision: 0.5426 - recall: 0.5600 - auc: 0.5518 - f1score: 0.5439 - val_loss: 8.2450 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5714 - val_recall: 0.6667 - val_auc: 0.6128 - val_f1score: 0.5994\n",
            "Epoch 34/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 30.8430 - accuracy: 0.5960 - c_accuracy: 0.5960 - precision: 0.6034 - recall: 0.5600 - auc: 0.6020 - f1score: 0.5955 - val_loss: 8.1844 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5333 - val_recall: 0.6667 - val_auc: 0.6464 - val_f1score: 0.5572\n",
            "Epoch 35/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 29.3127 - accuracy: 0.5760 - c_accuracy: 0.5760 - precision: 0.5826 - recall: 0.5360 - auc: 0.5954 - f1score: 0.5753 - val_loss: 8.5535 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5294 - val_recall: 0.7500 - val_auc: 0.6384 - val_f1score: 0.5484\n",
            "Epoch 36/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 29.2215 - accuracy: 0.5560 - c_accuracy: 0.5560 - precision: 0.5538 - recall: 0.5760 - auc: 0.5589 - f1score: 0.5558 - val_loss: 8.5702 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5556 - val_recall: 0.8333 - val_auc: 0.6480 - val_f1score: 0.5833\n",
            "Epoch 37/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 31.7197 - accuracy: 0.5560 - c_accuracy: 0.5560 - precision: 0.5522 - recall: 0.5920 - auc: 0.5606 - f1score: 0.5554 - val_loss: 8.0960 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5294 - val_recall: 0.7500 - val_auc: 0.6368 - val_f1score: 0.5484\n",
            "Epoch 38/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 30.0883 - accuracy: 0.5560 - c_accuracy: 0.5560 - precision: 0.5556 - recall: 0.5600 - auc: 0.5717 - f1score: 0.5560 - val_loss: 7.6446 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5333 - val_recall: 0.6667 - val_auc: 0.6496 - val_f1score: 0.5572\n",
            "Epoch 39/150\n",
            "8/8 [==============================] - 24s 3s/step - loss: 27.3839 - accuracy: 0.5880 - c_accuracy: 0.5880 - precision: 0.5821 - recall: 0.6240 - auc: 0.5939 - f1score: 0.5875 - val_loss: 7.3484 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.6154 - val_recall: 0.6667 - val_auc: 0.6592 - val_f1score: 0.6400\n",
            "Epoch 40/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 30.3782 - accuracy: 0.5320 - c_accuracy: 0.5320 - precision: 0.5317 - recall: 0.5360 - auc: 0.5403 - f1score: 0.5320 - val_loss: 7.5313 - val_accuracy: 0.5200 - val_c_accuracy: 0.5200 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6288 - val_f1score: 0.5130\n",
            "Epoch 41/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 27.4894 - accuracy: 0.5920 - c_accuracy: 0.5920 - precision: 0.5891 - recall: 0.6080 - auc: 0.6125 - f1score: 0.5919 - val_loss: 7.3624 - val_accuracy: 0.5200 - val_c_accuracy: 0.5200 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6320 - val_f1score: 0.5130\n",
            "Epoch 42/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.9186 - accuracy: 0.6040 - c_accuracy: 0.6040 - precision: 0.6048 - recall: 0.6000 - auc: 0.6244 - f1score: 0.6040 - val_loss: 7.3218 - val_accuracy: 0.5200 - val_c_accuracy: 0.5200 - val_precision: 0.5000 - val_recall: 0.6667 - val_auc: 0.6352 - val_f1score: 0.5130\n",
            "Epoch 43/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 25.3676 - accuracy: 0.6000 - c_accuracy: 0.6000 - precision: 0.5926 - recall: 0.6400 - auc: 0.6168 - f1score: 0.5994 - val_loss: 6.8421 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.6154 - val_recall: 0.6667 - val_auc: 0.6592 - val_f1score: 0.6400\n",
            "Epoch 44/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 29.3095 - accuracy: 0.5440 - c_accuracy: 0.5440 - precision: 0.5524 - recall: 0.4640 - auc: 0.5592 - f1score: 0.5411 - val_loss: 6.9359 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5333 - val_recall: 0.6667 - val_auc: 0.6368 - val_f1score: 0.5572\n",
            "Epoch 45/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 29.7302 - accuracy: 0.6080 - c_accuracy: 0.6080 - precision: 0.6216 - recall: 0.5520 - auc: 0.6192 - f1score: 0.6068 - val_loss: 7.9044 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6480 - val_f1score: 0.6180\n",
            "Epoch 46/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.1911 - accuracy: 0.5880 - c_accuracy: 0.5880 - precision: 0.5797 - recall: 0.6400 - auc: 0.5805 - f1score: 0.5869 - val_loss: 8.4635 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6352 - val_f1score: 0.6180\n",
            "Epoch 47/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 28.7640 - accuracy: 0.5960 - c_accuracy: 0.5960 - precision: 0.5870 - recall: 0.6480 - auc: 0.5948 - f1score: 0.5949 - val_loss: 7.7507 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6480 - val_f1score: 0.6180\n",
            "Epoch 48/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 28.9849 - accuracy: 0.5360 - c_accuracy: 0.5360 - precision: 0.5338 - recall: 0.5680 - auc: 0.5314 - f1score: 0.5355 - val_loss: 6.8483 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5294 - val_recall: 0.7500 - val_auc: 0.6400 - val_f1score: 0.5484\n",
            "Epoch 49/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.7218 - accuracy: 0.5960 - c_accuracy: 0.5960 - precision: 0.5968 - recall: 0.5920 - auc: 0.6149 - f1score: 0.5960 - val_loss: 6.2351 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.6154 - val_recall: 0.6667 - val_auc: 0.7056 - val_f1score: 0.6400\n",
            "Epoch 50/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 29.2847 - accuracy: 0.6040 - c_accuracy: 0.6040 - precision: 0.6083 - recall: 0.5840 - auc: 0.6115 - f1score: 0.6038 - val_loss: 6.4028 - val_accuracy: 0.5600 - val_c_accuracy: 0.5600 - val_precision: 0.5333 - val_recall: 0.6667 - val_auc: 0.6464 - val_f1score: 0.5572\n",
            "Epoch 51/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 27.0461 - accuracy: 0.6000 - c_accuracy: 0.6000 - precision: 0.5984 - recall: 0.6080 - auc: 0.6144 - f1score: 0.6000 - val_loss: 6.4424 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.6704 - val_f1score: 0.6667\n",
            "Epoch 52/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 28.5563 - accuracy: 0.5640 - c_accuracy: 0.5640 - precision: 0.5667 - recall: 0.5440 - auc: 0.5752 - f1score: 0.5638 - val_loss: 6.6868 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6752 - val_f1score: 0.6180\n",
            "Epoch 53/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 28.3756 - accuracy: 0.6000 - c_accuracy: 0.6000 - precision: 0.5940 - recall: 0.6320 - auc: 0.5953 - f1score: 0.5996 - val_loss: 5.9925 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5625 - val_recall: 0.7500 - val_auc: 0.6816 - val_f1score: 0.5942\n",
            "Epoch 54/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 28.2306 - accuracy: 0.5680 - c_accuracy: 0.5680 - precision: 0.5780 - recall: 0.5040 - auc: 0.5613 - f1score: 0.5662 - val_loss: 6.2210 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.6768 - val_f1score: 0.6667\n",
            "Epoch 55/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 29.2176 - accuracy: 0.5800 - c_accuracy: 0.5800 - precision: 0.5781 - recall: 0.5920 - auc: 0.5802 - f1score: 0.5799 - val_loss: 6.9841 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6848 - val_f1score: 0.6180\n",
            "Epoch 56/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 25.9275 - accuracy: 0.6400 - c_accuracy: 0.6400 - precision: 0.6336 - recall: 0.6640 - auc: 0.6560 - f1score: 0.6398 - val_loss: 6.6181 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6960 - val_f1score: 0.6180\n",
            "Epoch 57/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 27.2097 - accuracy: 0.6200 - c_accuracy: 0.6200 - precision: 0.6119 - recall: 0.6560 - auc: 0.6222 - f1score: 0.6195 - val_loss: 6.5339 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6976 - val_f1score: 0.6180\n",
            "Epoch 58/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.4914 - accuracy: 0.5920 - c_accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - auc: 0.5984 - f1score: 0.5920 - val_loss: 6.4738 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6976 - val_f1score: 0.6180\n",
            "Epoch 59/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.4907 - accuracy: 0.5920 - c_accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - auc: 0.5974 - f1score: 0.5920 - val_loss: 6.0223 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.6896 - val_f1score: 0.6667\n",
            "Epoch 60/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.4707 - accuracy: 0.6360 - c_accuracy: 0.6360 - precision: 0.6288 - recall: 0.6640 - auc: 0.6557 - f1score: 0.6357 - val_loss: 5.6254 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.7168 - val_f1score: 0.6667\n",
            "Epoch 61/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.5432 - accuracy: 0.5880 - c_accuracy: 0.5880 - precision: 0.5902 - recall: 0.5760 - auc: 0.5797 - f1score: 0.5879 - val_loss: 5.4671 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.7168 - val_f1score: 0.6667\n",
            "Epoch 62/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 25.8359 - accuracy: 0.6080 - c_accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - auc: 0.6187 - f1score: 0.6080 - val_loss: 5.2388 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7168 - val_f1score: 0.7126\n",
            "Epoch 63/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.6774 - accuracy: 0.5640 - c_accuracy: 0.5640 - precision: 0.5727 - recall: 0.5040 - auc: 0.5924 - f1score: 0.5624 - val_loss: 5.7395 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.6960 - val_f1score: 0.6667\n",
            "Epoch 64/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.8199 - accuracy: 0.6520 - c_accuracy: 0.6520 - precision: 0.6583 - recall: 0.6320 - auc: 0.6505 - f1score: 0.6519 - val_loss: 6.6111 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.6848 - val_f1score: 0.6180\n",
            "Epoch 65/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.4299 - accuracy: 0.6080 - c_accuracy: 0.6080 - precision: 0.6063 - recall: 0.6160 - auc: 0.6043 - f1score: 0.6080 - val_loss: 7.1451 - val_accuracy: 0.6000 - val_c_accuracy: 0.6000 - val_precision: 0.5500 - val_recall: 0.9167 - val_auc: 0.6544 - val_f1score: 0.5660\n",
            "Epoch 66/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 25.6823 - accuracy: 0.6160 - c_accuracy: 0.6160 - precision: 0.5973 - recall: 0.7120 - auc: 0.6122 - f1score: 0.6124 - val_loss: 5.8530 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.7088 - val_f1score: 0.6667\n",
            "Epoch 67/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 25.8749 - accuracy: 0.6120 - c_accuracy: 0.6120 - precision: 0.6186 - recall: 0.5840 - auc: 0.6325 - f1score: 0.6117 - val_loss: 4.9609 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7280 - val_f1score: 0.7126\n",
            "Epoch 68/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.4660 - accuracy: 0.5920 - c_accuracy: 0.5920 - precision: 0.6000 - recall: 0.5520 - auc: 0.5973 - f1score: 0.5913 - val_loss: 4.9307 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7312 - val_f1score: 0.7126\n",
            "Epoch 69/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.4439 - accuracy: 0.6000 - c_accuracy: 0.6000 - precision: 0.5954 - recall: 0.6240 - auc: 0.5977 - f1score: 0.5998 - val_loss: 4.9405 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7280 - val_f1score: 0.7126\n",
            "Epoch 70/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.9049 - accuracy: 0.6280 - c_accuracy: 0.6280 - precision: 0.6429 - recall: 0.5760 - auc: 0.6269 - f1score: 0.6270 - val_loss: 5.4198 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.7408 - val_f1score: 0.6667\n",
            "Epoch 71/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 25.1853 - accuracy: 0.5680 - c_accuracy: 0.5680 - precision: 0.5603 - recall: 0.6320 - auc: 0.5895 - f1score: 0.5662 - val_loss: 5.7059 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.7328 - val_f1score: 0.6667\n",
            "Epoch 72/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.7817 - accuracy: 0.6600 - c_accuracy: 0.6600 - precision: 0.6515 - recall: 0.6880 - auc: 0.6658 - f1score: 0.6597 - val_loss: 4.7806 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7392 - val_f1score: 0.7126\n",
            "Epoch 73/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.8981 - accuracy: 0.6400 - c_accuracy: 0.6400 - precision: 0.6446 - recall: 0.6240 - auc: 0.6493 - f1score: 0.6399 - val_loss: 4.5839 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7856 - val_f1score: 0.7565\n",
            "Epoch 74/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 25.2750 - accuracy: 0.6320 - c_accuracy: 0.6320 - precision: 0.6241 - recall: 0.6640 - auc: 0.6446 - f1score: 0.6316 - val_loss: 4.8588 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7344 - val_f1score: 0.7126\n",
            "Epoch 75/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.3624 - accuracy: 0.6720 - c_accuracy: 0.6720 - precision: 0.6720 - recall: 0.6720 - auc: 0.6782 - f1score: 0.6720 - val_loss: 4.8173 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7344 - val_f1score: 0.7126\n",
            "Epoch 76/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 25.3057 - accuracy: 0.5760 - c_accuracy: 0.5760 - precision: 0.5725 - recall: 0.6000 - auc: 0.5784 - f1score: 0.5758 - val_loss: 4.6271 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7472 - val_f1score: 0.7565\n",
            "Epoch 77/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 27.1429 - accuracy: 0.5520 - c_accuracy: 0.5520 - precision: 0.5556 - recall: 0.5200 - auc: 0.5756 - f1score: 0.5515 - val_loss: 4.8494 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7264 - val_f1score: 0.7126\n",
            "Epoch 78/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 25.4132 - accuracy: 0.5840 - c_accuracy: 0.5840 - precision: 0.5766 - recall: 0.6320 - auc: 0.6065 - f1score: 0.5830 - val_loss: 4.7164 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7376 - val_f1score: 0.7126\n",
            "Epoch 79/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 25.3577 - accuracy: 0.5840 - c_accuracy: 0.5840 - precision: 0.5868 - recall: 0.5680 - auc: 0.6169 - f1score: 0.5839 - val_loss: 4.4737 - val_accuracy: 0.8000 - val_c_accuracy: 0.8000 - val_precision: 0.7333 - val_recall: 0.9167 - val_auc: 0.7904 - val_f1score: 0.7987\n",
            "Epoch 80/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 24.8729 - accuracy: 0.5840 - c_accuracy: 0.5840 - precision: 0.5854 - recall: 0.5760 - auc: 0.6007 - f1score: 0.5840 - val_loss: 4.3347 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6923 - val_recall: 0.7500 - val_auc: 0.7896 - val_f1score: 0.7200\n",
            "Epoch 81/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 24.0829 - accuracy: 0.6240 - c_accuracy: 0.6240 - precision: 0.6325 - recall: 0.5920 - auc: 0.6361 - f1score: 0.6236 - val_loss: 4.2526 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6923 - val_recall: 0.7500 - val_auc: 0.7936 - val_f1score: 0.7200\n",
            "Epoch 82/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 26.2756 - accuracy: 0.5480 - c_accuracy: 0.5480 - precision: 0.5536 - recall: 0.4960 - auc: 0.5741 - f1score: 0.5468 - val_loss: 4.6242 - val_accuracy: 0.8000 - val_c_accuracy: 0.8000 - val_precision: 0.7333 - val_recall: 0.9167 - val_auc: 0.7360 - val_f1score: 0.7987\n",
            "Epoch 83/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.2560 - accuracy: 0.6200 - c_accuracy: 0.6200 - precision: 0.6210 - recall: 0.6160 - auc: 0.6417 - f1score: 0.6200 - val_loss: 4.9851 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7328 - val_f1score: 0.7126\n",
            "Epoch 84/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.3489 - accuracy: 0.6080 - c_accuracy: 0.6080 - precision: 0.6047 - recall: 0.6240 - auc: 0.6310 - f1score: 0.6079 - val_loss: 5.3836 - val_accuracy: 0.6400 - val_c_accuracy: 0.6400 - val_precision: 0.5789 - val_recall: 0.9167 - val_auc: 0.7168 - val_f1score: 0.6180\n",
            "Epoch 85/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.8396 - accuracy: 0.6920 - c_accuracy: 0.6920 - precision: 0.6875 - recall: 0.7040 - auc: 0.7164 - f1score: 0.6920 - val_loss: 5.4281 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.7264 - val_f1score: 0.6667\n",
            "Epoch 86/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.8430 - accuracy: 0.6400 - c_accuracy: 0.6400 - precision: 0.6357 - recall: 0.6560 - auc: 0.6387 - f1score: 0.6399 - val_loss: 5.1045 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7328 - val_f1score: 0.7126\n",
            "Epoch 87/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 22.8634 - accuracy: 0.6160 - c_accuracy: 0.6160 - precision: 0.6142 - recall: 0.6240 - auc: 0.6397 - f1score: 0.6160 - val_loss: 4.9698 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7392 - val_f1score: 0.7126\n",
            "Epoch 88/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 23.6304 - accuracy: 0.6200 - c_accuracy: 0.6200 - precision: 0.6154 - recall: 0.6400 - auc: 0.6358 - f1score: 0.6198 - val_loss: 4.9694 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6471 - val_recall: 0.9167 - val_auc: 0.7392 - val_f1score: 0.7126\n",
            "Epoch 89/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.2937 - accuracy: 0.6320 - c_accuracy: 0.6320 - precision: 0.6241 - recall: 0.6640 - auc: 0.6534 - f1score: 0.6316 - val_loss: 5.0510 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6111 - val_recall: 0.9167 - val_auc: 0.7344 - val_f1score: 0.6667\n",
            "Epoch 90/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 24.1568 - accuracy: 0.5920 - c_accuracy: 0.5920 - precision: 0.5891 - recall: 0.6080 - auc: 0.6127 - f1score: 0.5919 - val_loss: 4.7730 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7312 - val_f1score: 0.7565\n",
            "Epoch 91/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 23.6404 - accuracy: 0.6360 - c_accuracy: 0.6360 - precision: 0.6214 - recall: 0.6960 - auc: 0.6286 - f1score: 0.6347 - val_loss: 4.3698 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7696 - val_f1score: 0.7596\n",
            "Epoch 92/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.7869 - accuracy: 0.5960 - c_accuracy: 0.5960 - precision: 0.5968 - recall: 0.5920 - auc: 0.6189 - f1score: 0.5960 - val_loss: 4.1692 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.7273 - val_recall: 0.6667 - val_auc: 0.8016 - val_f1score: 0.7182\n",
            "Epoch 93/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 22.9792 - accuracy: 0.6160 - c_accuracy: 0.6160 - precision: 0.6218 - recall: 0.5920 - auc: 0.6277 - f1score: 0.6158 - val_loss: 4.1798 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.7273 - val_recall: 0.6667 - val_auc: 0.8032 - val_f1score: 0.7182\n",
            "Epoch 94/150\n",
            "8/8 [==============================] - 24s 3s/step - loss: 24.4326 - accuracy: 0.6080 - c_accuracy: 0.6080 - precision: 0.6216 - recall: 0.5520 - auc: 0.5948 - f1score: 0.6068 - val_loss: 4.4464 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7424 - val_f1score: 0.7596\n",
            "Epoch 95/150\n",
            "8/8 [==============================] - 24s 3s/step - loss: 21.6309 - accuracy: 0.6440 - c_accuracy: 0.6440 - precision: 0.6452 - recall: 0.6400 - auc: 0.6646 - f1score: 0.6440 - val_loss: 4.7374 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7312 - val_f1score: 0.7565\n",
            "Epoch 96/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.7547 - accuracy: 0.6560 - c_accuracy: 0.6560 - precision: 0.6466 - recall: 0.6880 - auc: 0.6765 - f1score: 0.6556 - val_loss: 4.6258 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7344 - val_f1score: 0.7565\n",
            "Epoch 97/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.3798 - accuracy: 0.6560 - c_accuracy: 0.6560 - precision: 0.6444 - recall: 0.6960 - auc: 0.6730 - f1score: 0.6554 - val_loss: 4.4012 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7576 - val_f1score: 0.7596\n",
            "Epoch 98/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 22.8245 - accuracy: 0.6000 - c_accuracy: 0.6000 - precision: 0.6016 - recall: 0.5920 - auc: 0.6287 - f1score: 0.6000 - val_loss: 4.3131 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7744 - val_f1score: 0.7596\n",
            "Epoch 99/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.0267 - accuracy: 0.6200 - c_accuracy: 0.6200 - precision: 0.6271 - recall: 0.5920 - auc: 0.6581 - f1score: 0.6197 - val_loss: 4.2782 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7696 - val_f1score: 0.7596\n",
            "Epoch 100/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.4773 - accuracy: 0.6280 - c_accuracy: 0.6280 - precision: 0.6231 - recall: 0.6480 - auc: 0.6471 - f1score: 0.6279 - val_loss: 4.1888 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.8000 - val_f1score: 0.7596\n",
            "Epoch 101/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.2718 - accuracy: 0.6520 - c_accuracy: 0.6520 - precision: 0.6667 - recall: 0.6080 - auc: 0.6672 - f1score: 0.6513 - val_loss: 4.0690 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.8048 - val_f1score: 0.7596\n",
            "Epoch 102/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.6650 - accuracy: 0.7040 - c_accuracy: 0.7040 - precision: 0.6977 - recall: 0.7200 - auc: 0.7138 - f1score: 0.7039 - val_loss: 4.2717 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7536 - val_f1score: 0.7565\n",
            "Epoch 103/150\n",
            "8/8 [==============================] - 24s 3s/step - loss: 23.9247 - accuracy: 0.6360 - c_accuracy: 0.6360 - precision: 0.6308 - recall: 0.6560 - auc: 0.6465 - f1score: 0.6359 - val_loss: 4.3486 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7344 - val_f1score: 0.7565\n",
            "Epoch 104/150\n",
            "8/8 [==============================] - 24s 3s/step - loss: 24.3665 - accuracy: 0.6800 - c_accuracy: 0.6800 - precision: 0.6718 - recall: 0.7040 - auc: 0.6776 - f1score: 0.6798 - val_loss: 4.1364 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7616 - val_f1score: 0.7565\n",
            "Epoch 105/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 22.5303 - accuracy: 0.6240 - c_accuracy: 0.6240 - precision: 0.6240 - recall: 0.6240 - auc: 0.6391 - f1score: 0.6240 - val_loss: 3.8580 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.8016 - val_f1score: 0.7596\n",
            "Epoch 106/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.7221 - accuracy: 0.6280 - c_accuracy: 0.6280 - precision: 0.6333 - recall: 0.6080 - auc: 0.6389 - f1score: 0.6279 - val_loss: 4.2314 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7344 - val_f1score: 0.7565\n",
            "Epoch 107/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.9367 - accuracy: 0.6720 - c_accuracy: 0.6720 - precision: 0.6569 - recall: 0.7200 - auc: 0.6961 - f1score: 0.6712 - val_loss: 4.0566 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7872 - val_f1score: 0.7565\n",
            "Epoch 108/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 24.3800 - accuracy: 0.6400 - c_accuracy: 0.6400 - precision: 0.6378 - recall: 0.6480 - auc: 0.6437 - f1score: 0.6400 - val_loss: 3.8788 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.8048 - val_f1score: 0.7596\n",
            "Epoch 109/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.6956 - accuracy: 0.6520 - c_accuracy: 0.6520 - precision: 0.6610 - recall: 0.6240 - auc: 0.6728 - f1score: 0.6517 - val_loss: 3.7701 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6923 - val_recall: 0.7500 - val_auc: 0.8048 - val_f1score: 0.7200\n",
            "Epoch 110/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 24.7425 - accuracy: 0.6160 - c_accuracy: 0.6160 - precision: 0.6160 - recall: 0.6160 - auc: 0.6292 - f1score: 0.6160 - val_loss: 4.0605 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7648 - val_f1score: 0.7565\n",
            "Epoch 111/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 22.4674 - accuracy: 0.6280 - c_accuracy: 0.6280 - precision: 0.6333 - recall: 0.6080 - auc: 0.6540 - f1score: 0.6279 - val_loss: 4.0860 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7616 - val_f1score: 0.7565\n",
            "Epoch 112/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.4012 - accuracy: 0.6800 - c_accuracy: 0.6800 - precision: 0.6772 - recall: 0.6880 - auc: 0.6969 - f1score: 0.6800 - val_loss: 4.1369 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7344 - val_f1score: 0.7565\n",
            "Epoch 113/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.7104 - accuracy: 0.6200 - c_accuracy: 0.6200 - precision: 0.6103 - recall: 0.6640 - auc: 0.6501 - f1score: 0.6193 - val_loss: 3.9549 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7920 - val_f1score: 0.7565\n",
            "Epoch 114/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 22.6424 - accuracy: 0.6120 - c_accuracy: 0.6120 - precision: 0.6077 - recall: 0.6320 - auc: 0.6243 - f1score: 0.6118 - val_loss: 3.8146 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.8016 - val_f1score: 0.7596\n",
            "Epoch 115/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.6534 - accuracy: 0.6520 - c_accuracy: 0.6520 - precision: 0.6462 - recall: 0.6720 - auc: 0.6717 - f1score: 0.6519 - val_loss: 3.6972 - val_accuracy: 0.6800 - val_c_accuracy: 0.6800 - val_precision: 0.6667 - val_recall: 0.6667 - val_auc: 0.8184 - val_f1score: 0.6795\n",
            "Epoch 116/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 22.1511 - accuracy: 0.6480 - c_accuracy: 0.6480 - precision: 0.6609 - recall: 0.6080 - auc: 0.6766 - f1score: 0.6474 - val_loss: 3.7112 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6923 - val_recall: 0.7500 - val_auc: 0.7984 - val_f1score: 0.7200\n",
            "Epoch 117/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 22.4982 - accuracy: 0.6520 - c_accuracy: 0.6520 - precision: 0.6610 - recall: 0.6240 - auc: 0.6740 - f1score: 0.6517 - val_loss: 3.9173 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7936 - val_f1score: 0.7565\n",
            "Epoch 118/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.2335 - accuracy: 0.6320 - c_accuracy: 0.6320 - precision: 0.6279 - recall: 0.6480 - auc: 0.6400 - f1score: 0.6319 - val_loss: 4.4903 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7568 - val_f1score: 0.7565\n",
            "Epoch 119/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.6691 - accuracy: 0.6440 - c_accuracy: 0.6440 - precision: 0.6343 - recall: 0.6800 - auc: 0.6607 - f1score: 0.6435 - val_loss: 4.1671 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7424 - val_f1score: 0.7565\n",
            "Epoch 120/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 19.5150 - accuracy: 0.7320 - c_accuracy: 0.7320 - precision: 0.7377 - recall: 0.7200 - auc: 0.7503 - f1score: 0.7320 - val_loss: 3.9010 - val_accuracy: 0.8000 - val_c_accuracy: 0.8000 - val_precision: 0.7333 - val_recall: 0.9167 - val_auc: 0.7888 - val_f1score: 0.7987\n",
            "Epoch 121/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.0015 - accuracy: 0.6440 - c_accuracy: 0.6440 - precision: 0.6475 - recall: 0.6320 - auc: 0.6503 - f1score: 0.6439 - val_loss: 3.8176 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7984 - val_f1score: 0.7596\n",
            "Epoch 122/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 22.7512 - accuracy: 0.6080 - c_accuracy: 0.6080 - precision: 0.6098 - recall: 0.6000 - auc: 0.6255 - f1score: 0.6080 - val_loss: 3.8709 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7904 - val_f1score: 0.7596\n",
            "Epoch 123/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 22.2618 - accuracy: 0.5840 - c_accuracy: 0.5840 - precision: 0.5814 - recall: 0.6000 - auc: 0.5953 - f1score: 0.5839 - val_loss: 3.8882 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7872 - val_f1score: 0.7596\n",
            "Epoch 124/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 23.1367 - accuracy: 0.6480 - c_accuracy: 0.6480 - precision: 0.6391 - recall: 0.6800 - auc: 0.6446 - f1score: 0.6476 - val_loss: 3.7321 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6923 - val_recall: 0.7500 - val_auc: 0.8176 - val_f1score: 0.7200\n",
            "Epoch 125/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 21.2017 - accuracy: 0.6760 - c_accuracy: 0.6760 - precision: 0.6964 - recall: 0.6240 - auc: 0.6941 - f1score: 0.6751 - val_loss: 3.6734 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.7273 - val_recall: 0.6667 - val_auc: 0.8000 - val_f1score: 0.7182\n",
            "Epoch 126/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 21.5562 - accuracy: 0.6560 - c_accuracy: 0.6560 - precision: 0.6726 - recall: 0.6080 - auc: 0.6786 - f1score: 0.6552 - val_loss: 3.8685 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7552 - val_f1score: 0.7596\n",
            "Epoch 127/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.8464 - accuracy: 0.6160 - c_accuracy: 0.6160 - precision: 0.6074 - recall: 0.6560 - auc: 0.6296 - f1score: 0.6154 - val_loss: 4.0488 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7392 - val_f1score: 0.7565\n",
            "Epoch 128/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 21.0980 - accuracy: 0.6560 - c_accuracy: 0.6560 - precision: 0.6639 - recall: 0.6320 - auc: 0.6814 - f1score: 0.6558 - val_loss: 4.1617 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7552 - val_f1score: 0.7565\n",
            "Epoch 129/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 22.8769 - accuracy: 0.6600 - c_accuracy: 0.6600 - precision: 0.6587 - recall: 0.6640 - auc: 0.6590 - f1score: 0.6600 - val_loss: 3.9713 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.6667 - val_recall: 0.8333 - val_auc: 0.7384 - val_f1score: 0.7182\n",
            "Epoch 130/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 20.5790 - accuracy: 0.6880 - c_accuracy: 0.6880 - precision: 0.6794 - recall: 0.7120 - auc: 0.7172 - f1score: 0.6878 - val_loss: 3.7516 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7632 - val_f1score: 0.7596\n",
            "Epoch 131/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.2159 - accuracy: 0.6440 - c_accuracy: 0.6440 - precision: 0.6429 - recall: 0.6480 - auc: 0.6649 - f1score: 0.6440 - val_loss: 3.8040 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7600 - val_f1score: 0.7596\n",
            "Epoch 132/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 22.2709 - accuracy: 0.6720 - c_accuracy: 0.6720 - precision: 0.6693 - recall: 0.6800 - auc: 0.6990 - f1score: 0.6720 - val_loss: 3.7109 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7632 - val_f1score: 0.7596\n",
            "Epoch 133/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 19.8226 - accuracy: 0.7080 - c_accuracy: 0.7080 - precision: 0.6970 - recall: 0.7360 - auc: 0.7417 - f1score: 0.7078 - val_loss: 3.6986 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7632 - val_f1score: 0.7596\n",
            "Epoch 134/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 21.2239 - accuracy: 0.6800 - c_accuracy: 0.6800 - precision: 0.6923 - recall: 0.6480 - auc: 0.6917 - f1score: 0.6797 - val_loss: 3.8522 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.6875 - val_recall: 0.9167 - val_auc: 0.7632 - val_f1score: 0.7565\n",
            "Epoch 135/150\n",
            "8/8 [==============================] - 23s 3s/step - loss: 23.7419 - accuracy: 0.6320 - c_accuracy: 0.6320 - precision: 0.6204 - recall: 0.6800 - auc: 0.6376 - f1score: 0.6312 - val_loss: 3.5406 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7904 - val_f1score: 0.7596\n",
            "Epoch 136/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 20.9213 - accuracy: 0.6760 - c_accuracy: 0.6760 - precision: 0.6803 - recall: 0.6640 - auc: 0.6845 - f1score: 0.6760 - val_loss: 3.4588 - val_accuracy: 0.7200 - val_c_accuracy: 0.7200 - val_precision: 0.7273 - val_recall: 0.6667 - val_auc: 0.8320 - val_f1score: 0.7182\n",
            "Epoch 137/150\n",
            "8/8 [==============================] - 22s 3s/step - loss: 21.2488 - accuracy: 0.6600 - c_accuracy: 0.6600 - precision: 0.6639 - recall: 0.6480 - auc: 0.6802 - f1score: 0.6600 - val_loss: 3.6601 - val_accuracy: 0.7600 - val_c_accuracy: 0.7600 - val_precision: 0.7143 - val_recall: 0.8333 - val_auc: 0.7952 - val_f1score: 0.7596\n",
            "Epoch 138/150\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 20.1978 - accuracy: 0.7812 - c_accuracy: 0.7812 - precision: 0.8000 - recall: 0.7500 - auc: 0.7539 - f1score: 0.7810"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cdbcaea0140a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=config['TRAIN']['EPOCHS'],\n\u001b[1;32m      6\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                 verbose=True, class_weight=class_weight)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di1tZ7mKOmy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import save_model, load_model\n",
        "\n",
        "model_path = os.path.join(config['PATHS']['MODELS_FOLDER'], '{}{}{}'.format('model', cur_date, '.h5'))\n",
        "save_model(model, model_path)\n",
        "#model = load_model(config['PATHS']['MODEL_TO_LOAD'])\n",
        "#model.set_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOZOPWlqOuFB",
        "colab_type": "code",
        "outputId": "ca657081-6994-4568-e0d6-e6aac0431fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "test_results = model.evaluate_generator(test_generator, verbose=1)\n",
        "test_metrics = {}\n",
        "test_summary_str = [['**Metric**', '**Value**']]\n",
        "for metric, value in zip(model.metrics_names, test_results):\n",
        "    test_metrics[metric] = value\n",
        "    print(metric, ' = ', value)\n",
        "    test_summary_str.append([metric, str(value)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-6d312cbbd3a1>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8146 - accuracy: 0.8387 - c_accuracy: 0.8387 - precision: 0.7895 - recall: 0.9375 - auc: 0.8450 - f1score: 0.8360\n",
            "loss  =  4.814605712890625\n",
            "accuracy  =  0.8387096524238586\n",
            "c_accuracy  =  0.8387096524238586\n",
            "precision  =  0.7894737124443054\n",
            "recall  =  0.9375\n",
            "auc  =  0.844953179359436\n",
            "f1score  =  [0.85714287 0.8148148 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O9YUx_9pyGI",
        "colab_type": "code",
        "outputId": "ab3bfbee-2c9d-4f46-b1bc-0dbc9efebf28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "pip install lime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.6/dist-packages (0.2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.18.4)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: pillow==5.4.1 in /usr/local/lib/python3.6/dist-packages (from lime) (5.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (0.15.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZt4dWOVPi5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lime_dict = {\n",
        "  'NUM_SAMPLES': config['LIME']['NUM_SAMPLES'],\n",
        "  'NUM_FEATURES': config['LIME']['NUM_FEATURES'],\n",
        "  'IMG_PATH': config['PATHS']['IMAGES'],\n",
        "  'RAW_DATA_PATH': config['PATHS']['RAW_DATA'],\n",
        "  'IMG_DIM': config['DATA']['IMG_DIM'],\n",
        "  'PRED_THRESHOLD': config['PREDICTION']['THRESHOLD'],\n",
        "  'CLASSES': config['DATA']['CLASSES'],\n",
        "  'COVID_ONLY': config['LIME']['COVID_ONLY'],\n",
        "  'KERNEL_WIDTH': config['LIME']['KERNEL_WIDTH'],\n",
        "  'FEATURE_SELECTION': config['LIME']['FEATURE_SELECTION']\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF4S2Jb4PqkE",
        "colab_type": "code",
        "outputId": "e07820fe-f42c-43b7-d887-b892c62efcd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from lime.lime_image import LimeImageExplainer\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "test_img_gen = ImageDataGenerator(samplewise_std_normalization=True, samplewise_center=True)\n",
        "\n",
        "NUM_TEST_IMG = data['TEST'].shape[0]\n",
        "\n",
        "lime_test_generator = test_img_gen.flow_from_dataframe(dataframe=data['TEST'],\n",
        "    x_col=\"filename\", y_col='label', target_size=tuple(config['DATA']['IMG_DIM']), batch_size=1,\n",
        "    class_mode='categorical', validate_filenames=False, shuffle=False)\n",
        "\n",
        "lime_explainer = LimeImageExplainer(kernel_width=lime_dict['KERNEL_WIDTH'], feature_selection=lime_dict['FEATURE_SELECTION'],\n",
        "                                            verbose=True)\n",
        "dill.dump(lime_explainer, open(config['PATHS']['LIME_EXPLAINER'], 'wb'))\n",
        "\n",
        "lime_model = load_model(config['PATHS']['MODEL_TO_LOAD'], compile=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 31 non-validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KBFRG7aut40",
        "colab_type": "code",
        "outputId": "38084680-f609-4c67-e55f-99ae9d750eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from lime.lime_image import SegmentationAlgorithm\n",
        "\n",
        "def visualize_explanation(orig_img, explanation, img_filename, label, probs, class_names, label_to_see='top', dir_path=None):\n",
        "\n",
        "    # Plot original image on the left\n",
        "    fig, ax = plt.subplots(1, 2)\n",
        "    ax[0].imshow(orig_img)\n",
        "\n",
        "    # Plot the image and its explanation on the right\n",
        "    if label_to_see == 'top':\n",
        "        label_to_see = explanation.top_labels[0]\n",
        "    explanation.image = orig_img\n",
        "    temp, mask = explanation.get_image_and_mask(label_to_see, positive_only=False, num_features=10, hide_rest=False)\n",
        "    ax[1].imshow(mark_boundaries(temp, mask))\n",
        "\n",
        "    # Display some information about the example\n",
        "    pred_class = np.argmax(probs)\n",
        "    fig.text(0.5, 0.9, \"Prediction probabilities: \" + str(['{:.2f}'.format(probs[i]) for i in range(len(probs))]),\n",
        "             fontsize=10)\n",
        "    fig.text(0.02, 0.9, \"Predicted Class: \" + str(pred_class) + ' (' + class_names[int(pred_class)] + ')', fontsize=10)\n",
        "    if label is not None:\n",
        "        fig.text(0.02, 0.85, \"Ground Truth Class: \" + str(class_names.index(label)) + ' (' + label + ')', fontsize=10)\n",
        "    fig.suptitle(\"LIME Explanation for image \" + img_filename, fontsize=13)\n",
        "    fig.tight_layout()\n",
        "\n",
        "    # Save the image\n",
        "    filename = None\n",
        "    if dir_path is not None:\n",
        "        if not os.path.exists(dir_path):\n",
        "            os.makedirs(dir_path)\n",
        "        filename = os.path.join(dir_path, img_filename.split('/')[-1] + '_exp_' + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '.svg')\n",
        "        plt.savefig(filename)\n",
        "    return filename\n",
        "\n",
        "lime_test_generator.reset()\n",
        "for idx in range(NUM_TEST_IMG):\n",
        "  x, _ = lime_test_generator.next()\n",
        "  x = np.squeeze(x, axis=0)\n",
        "\n",
        "  # Get the corresponding original image (no preprocessing)\n",
        "  orig_img = cv2.imread(data['TEST']['filename'][idx])\n",
        "  new_dim = tuple(lime_dict['IMG_DIM'])\n",
        "  orig_img = cv2.resize(orig_img, new_dim, interpolation=cv2.INTER_NEAREST)     # Resize image\n",
        "\n",
        "  # Make a prediction for this image and retrieve a LIME explanation for the prediction\n",
        "  start_time = datetime.datetime.now()\n",
        "\n",
        "  def predict(x):\n",
        "      '''\n",
        "      Helper function for LIME explainer. Runs model prediction on perturbations of the example.\n",
        "      :param x: List of perturbed examples from an example\n",
        "      :return: A numpy array constituting a list of class probabilities for each predicted perturbation\n",
        "      '''\n",
        "      y = lime_model.predict(x)  # Run prediction on the perturbations\n",
        "      if y.shape[1] == 1:\n",
        "          probs = np.concatenate([1.0 - y, y], axis=1)  # Compute class probabilities from the output of the model\n",
        "      else:\n",
        "          probs = y\n",
        "      return probs\n",
        "\n",
        "  # Algorithm for superpixel segmentation. Parameters set to limit size of superpixels and promote border smoothness\n",
        "  segmentation_fn = SegmentationAlgorithm('quickshift', kernel_size=2.25, max_dist=50, ratio=0.1, sigma=0.15)\n",
        "  # Generate explanation for the example\n",
        "  explanation = lime_explainer.explain_instance(x.astype(np.double), predict, num_features=lime_dict['NUM_FEATURES'], num_samples=lime_dict['NUM_SAMPLES'], segmentation_fn=segmentation_fn)\n",
        "  probs = predict(np.expand_dims(x, axis=0))\n",
        "\n",
        "  print(\"Explanation time = \" + str((datetime.datetime.now() - start_time).total_seconds()) + \" seconds\")\n",
        "\n",
        "  # Get image filename and label\n",
        "  img_filename = data['TEST']['filename'][idx]\n",
        "  label = data['TEST']['label'][idx]\n",
        "\n",
        "  # Rearrange prediction probability vector to reflect original ordering of classes in project config\n",
        "  probs = [probs[0][lime_dict['CLASSES'].index(c)] for c in lime_test_generator.class_indices]\n",
        "\n",
        "  # Visualize the LIME explanation and optionally save it to disk\n",
        "  file_path = lime_dict['IMG_PATH']\n",
        "  explanation_filenames = []\n",
        "  if lime_dict['COVID_ONLY'] == True:\n",
        "      label_to_see = lime_test_generator.class_indices['COVID-19']\n",
        "  else:\n",
        "      label_to_see = 'top'\n",
        "  expalanation_filename = visualize_explanation(orig_img, explanation, img_filename, label, probs, lime_dict['CLASSES'], label_to_see=label_to_see,\n",
        "                        dir_path=file_path)\n",
        "  explanation_filenames.append(expalanation_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e7b6083467a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0msegmentation_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSegmentationAlgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quickshift'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;31m# Generate explanation for the example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0mexplanation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlime_explainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlime_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NUM_FEATURES'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlime_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NUM_SAMPLES'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegmentation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegmentation_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lime/lime_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    198\u001b[0m         data, labels = self.data_labels(image, fudged_image, segments,\n\u001b[1;32m    199\u001b[0m                                         \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                                         batch_size=batch_size)\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         distances = sklearn.metrics.pairwise_distances(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lime/lime_image.py\u001b[0m in \u001b[0;36mdata_labels\u001b[0;34m(self, image, fudged_image, segments, classifier_fn, num_samples, batch_size)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                 \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegments\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfudged_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}